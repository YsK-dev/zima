{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# Lightning.ai Data Generation - 100% Local GPU\n",
                "\n",
                "This notebook generates synthetic geriatric health data using:\n",
                "- **NVIDIA L40 GPU** (48GB VRAM)\n",
                "- **Qwen 2.5 14B** model (local, no API)\n",
                "- **Target**: 50,000 samples (18,000 per 3.5-hour session)\n",
                "\n",
                "## Instructions\n",
                "1. Make sure you uploaded: `intents.json`, `claude.json`, `gemini.json`\n",
                "2. Run all cells in order\n",
                "3. Download `synthetic_geriatric_data.jsonl` when complete"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Step 1: Install Ollama"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Install Ollama\n",
                "!curl -fsSL https://ollama.com/install.sh | sh"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Step 2: Start Ollama Server"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Start Ollama in background\n",
                "!nohup ollama serve > /tmp/ollama.log 2>&1 &\n",
                "!sleep 10\n",
                "\n",
                "# Check if running\n",
                "!pgrep -x ollama && echo \"✓ Ollama is running\" || echo \"❌ Ollama failed to start\""
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Step 3: Pull Qwen 14B Model (~10 minutes)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Pull the Qwen 14B model (optimized for L40 GPU)\n",
                "!ollama pull qwen2.5:14b"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Step 4: Install Python Dependencies"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "!pip install -q openai pandas"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Step 5: Check GPU"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "!nvidia-smi --query-gpu=name,memory.total,memory.free --format=csv"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Step 6: Verify Uploaded Files"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "import os\n",
                "from pathlib import Path\n",
                "\n",
                "# Check for seed files\n",
                "seed_files = ['intents.json', 'claude.json', 'gemini.json']\n",
                "found = []\n",
                "missing = []\n",
                "\n",
                "for f in seed_files:\n",
                "    if Path(f).exists():\n",
                "        found.append(f)\n",
                "        print(f\"✓ Found: {f}\")\n",
                "    else:\n",
                "        missing.append(f)\n",
                "        print(f\"❌ Missing: {f}\")\n",
                "\n",
                "if missing:\n",
                "    print(f\"\\n⚠️  Please upload: {', '.join(missing)}\")\n",
                "else:\n",
                "    print(f\"\\n✅ All seed files ready!\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Step 7: Run Data Generation\n",
                "\n",
                "**This will take ~3.5 hours**. The script auto-stops before the 4-hour limit."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Run the generation script\n",
                "# Make sure data_creation_lightning.py is uploaded\n",
                "!python data_creation_lightning.py"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Alternative: Run Generation Code Directly in Notebook\n",
                "\n",
                "If you don't have the `.py` file, run this cell instead:"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Paste the entire contents of data_creation_lightning.py here and run\n",
                "# Or use the cell above if you uploaded the .py file"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Step 8: Monitor Progress (Optional)\n",
                "\n",
                "Run this in a separate notebook or terminal to watch progress:"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Check number of samples generated so far\n",
                "!wc -l synthetic_geriatric_data.jsonl 2>/dev/null || echo \"File not created yet\""
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Check GPU usage\n",
                "!nvidia-smi"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Step 9: View Sample Output"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "import json\n",
                "\n",
                "# Display first 3 samples\n",
                "try:\n",
                "    with open('synthetic_geriatric_data.jsonl', 'r') as f:\n",
                "        for i, line in enumerate(f):\n",
                "            if i >= 3:\n",
                "                break\n",
                "            sample = json.loads(line)\n",
                "            print(f\"\\n--- Sample {i+1} ---\")\n",
                "            print(f\"Instruction: {sample['instruction']}\")\n",
                "            print(f\"Input: {sample['input']}\")\n",
                "            print(f\"Output: {sample['output']}\")\n",
                "except FileNotFoundError:\n",
                "    print(\"Output file not found yet. Generation may still be running.\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Step 10: Download Results\n",
                "\n",
                "When generation is complete:\n",
                "1. Go to the file browser (left sidebar)\n",
                "2. Right-click `synthetic_geriatric_data.jsonl`\n",
                "3. Select **Download**\n",
                "\n",
                "Or use this code to check final count:"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Final statistics\n",
                "!wc -l synthetic_geriatric_data.jsonl\n",
                "!ls -lh synthetic_geriatric_data.jsonl"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.10.0"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 4
}